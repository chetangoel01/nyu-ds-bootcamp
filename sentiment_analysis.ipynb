{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ef3f64",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Social Media Content\n",
    "### Week 5 Presentation\n",
    "\n",
    "This notebook presents our work on analyzing a Social Media Sentiment Analysis Dataset. In the following sections, we:\n",
    "- Explore and clean the dataset\n",
    "- Perform sentiment analysis and visualize the sentiment distribution\n",
    "- Analyze temporal trends using the timestamp data\n",
    "- Investigate user engagement metrics (Likes and Retweets) and their relationship to sentiment\n",
    "- Examine platform-specific trends, trending hashtags, and geographical differences\n",
    "- (Optional) Build a simple predictive model to estimate user engagement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97837781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87729f24",
   "metadata": {},
   "source": [
    "## Dataset Exploration\n",
    "\n",
    "We begin by loading the dataset and exploring its structure. Note that our dataset contains extra columns (`Unnamed: 0.1`, `Unnamed: 0`) that we will drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Replace 'social_media_sentiment.csv' with the correct file path if needed\n",
    "try:\n",
    "    df = pd.read_csv('social_media_sentiment.csv')\n",
    "except Exception as e:\n",
    "    print('Error loading dataset:', e)\n",
    "\n",
    "# Drop unwanted unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Basic info and summary\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print('Missing values in each column:')\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e2f37",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "We visualize the distribution of sentiments across the dataset using the **Sentiment** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83aa569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(data=df, x='Sentiment', order=df['Sentiment'].value_counts().index)\n",
    "plt.title('Distribution of Sentiments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b818f",
   "metadata": {},
   "source": [
    "## Temporal Analysis\n",
    "\n",
    "We convert the **Timestamp** column into a datetime object and analyze how posts evolve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Timestamp' to datetime (if not already)\n",
    "if not np.issubdtype(df['Timestamp'].dtype, np.datetime64):\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "\n",
    "# Create a new 'date' column\n",
    "df['date'] = df['Timestamp'].dt.date\n",
    "\n",
    "# Plot the number of posts over time\n",
    "plt.figure(figsize=(12,6))\n",
    "df.groupby('date').size().plot()\n",
    "plt.title('Number of Posts Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Posts')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef20f09",
   "metadata": {},
   "source": [
    "## User Engagement Insights\n",
    "\n",
    "We study the distribution of user engagement metrics (**Likes** and **Retweets**) and analyze how they vary with sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for Likes and Retweets\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df['Likes'], kde=True)\n",
    "plt.title('Distribution of Likes')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df['Retweets'], kde=True)\n",
    "plt.title('Distribution of Retweets')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots to compare engagement across sentiments\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(data=df, x='Sentiment', y='Likes', order=df['Sentiment'].value_counts().index)\n",
    "plt.title('Likes by Sentiment')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data=df, x='Sentiment', y='Retweets', order=df['Sentiment'].value_counts().index)\n",
    "plt.title('Retweets by Sentiment')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Engagement correlation heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df[['Likes','Retweets']].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Engagement Metrics Correlation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42c6eb",
   "metadata": {},
   "source": [
    "## Platform-Specific Analysis\n",
    "\n",
    "We now compare sentiment trends and post counts across different social media platforms using the **Platform** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb15950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posts per platform\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(data=df, x='Platform', order=df['Platform'].value_counts().index)\n",
    "plt.title('Posts by Platform')\n",
    "plt.xlabel('Platform')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Sentiment distribution per platform\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=df, x='Platform', hue='Sentiment', order=df['Platform'].value_counts().index)\n",
    "plt.title('Sentiment Distribution by Platform')\n",
    "plt.xlabel('Platform')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Sentiment')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a291c4",
   "metadata": {},
   "source": [
    "## Hashtag and Topic Trends\n",
    "\n",
    "We analyze trending hashtags and investigate their relationship with user engagement. The **Hashtags** column is processed to extract individual hashtags. In our dataset, hashtags may be separated by commas or whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze hashtag trends\n",
    "if 'Hashtags' in df.columns:\n",
    "    # Replace missing hashtags with an empty string\n",
    "    df['Hashtags'] = df['Hashtags'].fillna('')\n",
    "    \n",
    "    # Create a new column for hashtags list\n",
    "    def split_hashtags(x):\n",
    "        x = x.strip()\n",
    "        if not x:\n",
    "            return []\n",
    "        # If comma exists, split by comma; otherwise, split by whitespace\n",
    "        if ',' in x:\n",
    "            return [tag.strip() for tag in x.split(',') if tag.strip()]\n",
    "        else:\n",
    "            return [tag.strip() for tag in x.split() if tag.strip()]\n",
    "    \n",
    "    df['hashtags_list'] = df['Hashtags'].apply(split_hashtags)\n",
    "    \n",
    "    # Explode the list so each hashtag gets its own row\n",
    "    hashtags_exploded = df.explode('hashtags_list')\n",
    "    \n",
    "    # Remove empty hashtag entries\n",
    "    hashtags_exploded = hashtags_exploded[hashtags_exploded['hashtags_list'] != '']\n",
    "    \n",
    "    # Top 20 hashtags\n",
    "    top_hashtags = hashtags_exploded['hashtags_list'].value_counts().head(20)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x=top_hashtags.values, y=top_hashtags.index, orient='h')\n",
    "    plt.title('Top 20 Hashtags')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Hashtag')\n",
    "    plt.show()\n",
    "    \n",
    "    # Average likes per hashtag (top 10)\n",
    "    hashtag_engagement = hashtags_exploded.groupby('hashtags_list')['Likes'].mean().sort_values(ascending=False).head(10)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x=hashtag_engagement.values, y=hashtag_engagement.index, orient='h')\n",
    "    plt.title('Top Hashtags by Average Likes')\n",
    "    plt.xlabel('Average Likes')\n",
    "    plt.ylabel('Hashtag')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No Hashtags column found in the dataset.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f0def",
   "metadata": {},
   "source": [
    "## Geographical Trends\n",
    "\n",
    "We examine how sentiment and engagement vary by geography using the **Country** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posts by country\n",
    "if 'Country' in df.columns:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.countplot(data=df, x='Country', order=df['Country'].value_counts().index)\n",
    "    plt.title('Posts by Country')\n",
    "    plt.xlabel('Country')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Sentiment distribution for top 10 countries\n",
    "    top_countries = df['Country'].value_counts().head(10).index\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.countplot(data=df[df['Country'].isin(top_countries)], x='Country', hue='Sentiment', order=top_countries)\n",
    "    plt.title('Sentiment Distribution by Country')\n",
    "    plt.xlabel('Country')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Sentiment')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No Country column found in the dataset.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b46b46",
   "metadata": {},
   "source": [
    "## Cross-Feature Analysis\n",
    "\n",
    "We combine multiple features to gain deeper insights. The following cell examines how average Likes evolve over time by platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cross-feature analysis: average Likes over time for each platform\n",
    "if 'Platform' in df.columns and 'date' in df.columns:\n",
    "    pivot_df = df.pivot_table(index='date', columns='Platform', values='Likes', aggfunc='mean')\n",
    "    plt.figure(figsize=(12,6))\n",
    "    pivot_df.plot()\n",
    "    plt.title('Average Likes Over Time by Platform')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Average Likes')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Platform')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Required columns for cross-feature analysis not found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77633342",
   "metadata": {},
   "source": [
    "## Predictive Modeling (Optional)\n",
    "\n",
    "Below is an example of building a simple linear regression model to predict user engagement (Likes) based on features such as **Sentiment** and **Platform**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modeling libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepare features for prediction\n",
    "features = []\n",
    "if 'Sentiment' in df.columns:\n",
    "    # Encode Sentiment to numeric\n",
    "    df['Sentiment_encoded'] = df['Sentiment'].astype('category').cat.codes\n",
    "    features.append('Sentiment_encoded')\n",
    "if 'Platform' in df.columns:\n",
    "    df['Platform_encoded'] = df['Platform'].astype('category').cat.codes\n",
    "    features.append('Platform_encoded')\n",
    "\n",
    "# Ensure we have a target and features\n",
    "if 'Likes' in df.columns and features:\n",
    "    X = df[features].fillna(0)\n",
    "    y = df['Likes'].fillna(0)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create and train the linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print('Mean Squared Error:', mse)\n",
    "\n",
    "    # Visualize predicted vs. actual Likes\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.title('Predicted vs Actual Likes')\n",
    "    plt.xlabel('Actual Likes')\n",
    "    plt.ylabel('Predicted Likes')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Required columns for predictive modeling not found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe6205",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored the social media sentiment dataset and uncovered insights related to sentiment, temporal trends, user engagement, platform specifics, hashtag trends, and geographical variations.\n",
    "\n",
    "### Future Work\n",
    "- Enhance predictive models with additional features (e.g., hashtag counts, more granular time features).\n",
    "- Perform deeper analysis into regional sentiment trends and seasonal variations.\n",
    "- Explore more advanced sentiment analysis techniques and natural language processing approaches.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
